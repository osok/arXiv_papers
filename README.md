# arXiv_papers

I used the tools I built in ```https://github.com/osok/fabric_tools``` to process the files in you tube channel ```https://www.youtube.com/@ArxivPapers``` with fabric ```https://github.com/danielmiessler/fabric```.  

1) Transcribe the youtube video, which itself is based on the PDF of the same name.
2) I ran that through fabric using the extract_wisdom prompt
3) I then extracted the summary, single line extract and the Items from that into ```overview.md```



The papers processed can be found in ```processed.md```



I will continue to add more each day.  The scrips in ```fabric_tools``` don't process duplicates.  I just cannot afford to over run my OpenAI limits.

