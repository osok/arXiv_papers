# SUMMARY
Researchers at Durham University explore the impact of advanced large language models (LLMs) on coding assessments in a 10-week physics coding course.

# IDEAS:
- Coding courses are increasingly included in university programs worldwide, highlighting programming skills' growing importance.
- Advanced LLMs like Codex prompt reconsideration of coding assessments in educational settings.
- The study focuses on AI's impact on practical coding curriculum in a 10-week physics course.
- Physics degrees involve diverse assessments, offering a unique opportunity to explore AI's impact.
- AI's influence on essay-based assessments is becoming more pronounced.
- LLMs are improving in their comprehension of physics concepts, approaching human levels.
- The study evaluates the ongoing relevance and integrity of coding assignments amidst technological advancements.
- The code used in the research is openly accessible on GitHub.
- The study uses a blinded marking approach to assess code written by students and AI.
- Physics coding emphasizes creating clear, well-labeled plots explaining physics scenarios.
- The study contrasts with computer science scenarios focusing on readability and maintainability.
- ChatGPT's suitability as a coding tool for physics education is evaluated.
- The study involves 14 plots assessed against a specific marking scheme in a 16-page report.
- The Python coding segment spans 10 weeks with weekly lectures and eight assignments.
- Pre-processing assignment notebooks is crucial for aligning with AI capabilities.
- Prompt engineering significantly improves AI performance.
- GPT-4 with prompt engineering scored 81.1%, while students averaged 91.1%.
- Combining student and AI work scored lower than AI-only submissions.
- Genuine student submissions were more accurately identified as student-authored.
- AI-generated content tended to be categorized closer to definitely AI or probably AI.
- Human-created content is generally of higher quality than AI-generated content.
- Educators should consider integrating AI into educational practices like pair programming tools.
- Extensive prompt engineering raises concerns about academic integrity.
- Markers successfully identified AI-generated work based on design differences and plot characteristics.

# INSIGHTS:
- Advanced LLMs prompt reconsideration of coding assessments in educational settings.
- Physics degrees' diverse assessments offer a unique opportunity to explore AI's impact.
- LLMs are improving in their comprehension of physics concepts, approaching human levels.
- Pre-processing assignment notebooks is crucial for aligning with AI capabilities.
- Prompt engineering significantly improves AI performance in coding tasks.
- Combining student and AI work scored lower than AI-only submissions.
- Human-created content is generally of higher quality than AI-generated content.
- Educators should consider integrating AI into educational practices like pair programming tools.
- Extensive prompt engineering raises concerns about academic integrity.
- Markers successfully identified AI-generated work based on design differences and plot characteristics.

# QUOTES:
- "Coding courses are increasingly included in university programs worldwide, highlighting programming skills' growing importance."
- "Advanced LLMs like Codex prompt reconsideration of coding assessments in educational settings."
- "The study focuses on AI's impact on practical coding curriculum in a 10-week physics course."
- "Physics degrees involve diverse assessments, offering a unique opportunity to explore AI's impact."
- "AI's influence on essay-based assessments is becoming more pronounced."
- "LLMs are improving in their comprehension of physics concepts, approaching human levels."
- "The study evaluates the ongoing relevance and integrity of coding assignments amidst technological advancements."
- "The code used in the research is openly accessible on GitHub."
- "The study uses a blinded marking approach to assess code written by students and AI."
- "Physics coding emphasizes creating clear, well-labeled plots explaining physics scenarios."
- "The study contrasts with computer science scenarios focusing on readability and maintainability."
- "ChatGPT's suitability as a coding tool for physics education is evaluated."
- "Pre-processing assignment notebooks is crucial for aligning with AI capabilities."
- "Prompt engineering significantly improves AI performance."
- "GPT-4 with prompt engineering scored 81.1%, while students averaged 91.1%."
- "Combining student and AI work scored lower than AI-only submissions."
- "Genuine student submissions were more accurately identified as student-authored."
- "AI-generated content tended to be categorized closer to definitely AI or probably AI."
- "Human-created content is generally of higher quality than AI-generated content."
- "Educators should consider integrating AI into educational practices like pair programming tools."

# HABITS:
- Pre-process assignment notebooks to align with AI capabilities before inputting them into the model.
- Use prompt engineering techniques to optimize AI responses for coding tasks.
- Evaluate coding assignments using a blinded marking approach for unbiased assessment.
- Collect and randomly select student submissions for evaluation to ensure fairness.
- Focus on creating clear, well-labeled plots that explain the physics behind scenarios.

# FACTS:
- Coding courses are increasingly included in university programs worldwide, highlighting programming skills' growing importance.
- Advanced LLMs like Codex prompt reconsideration of coding assessments in educational settings.
- Physics degrees involve diverse assessments, offering a unique opportunity to explore AI's impact.
- LLMs are improving in their comprehension of physics concepts, approaching human levels.
- Pre-processing assignment notebooks is crucial for aligning with AI capabilities.
- Prompt engineering significantly improves AI performance in coding tasks.
- GPT-4 with prompt engineering scored 81.1%, while students averaged 91.1%.
- Combining student and AI work scored lower than AI-only submissions.
- Human-created content is generally of higher quality than AI-generated content.
- Educators should consider integrating AI into educational practices like pair programming tools.

# REFERENCES:
- GitHub (for accessing the code used in the research)
  
# ONE-SENTENCE TAKEAWAY
Advanced LLMs like Codex prompt reconsideration of coding assessments, emphasizing the need for tailored prompt engineering.

# RECOMMENDATIONS:
- Integrate advanced LLMs into educational practices to enhance coding education effectiveness.
- Use prompt engineering techniques to optimize AI responses for coding tasks.
- Evaluate coding assignments using a blinded marking approach for unbiased assessment.
- Focus on creating clear, well-labeled plots that explain the physics behind scenarios.
- Consider the impact of pre-processing steps on the quality of the ai's output.