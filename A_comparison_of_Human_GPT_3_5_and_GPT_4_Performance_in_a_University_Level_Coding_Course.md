# SUMMARY
The study, conducted at Durham University, examines the impact of advanced large language models (LLMs) on coding assessments in a 10-week physics coding course.

# IDEAS:
- Coding courses are increasingly included in university programs worldwide, highlighting programming skills' growing importance.
- Advanced LLMs like Codex prompt reconsideration of coding assessments in educational settings.
- The study focuses on AI's impact on practical coding curriculum in a 10-week physics course.
- Physics degrees involve diverse assessments, including lab experiments, presentations, written exams, essays, and coding tasks.
- AI's influence on essay-based assessments is becoming more pronounced with high-quality AI-generated work.
- LLMs are improving in their comprehension of physics concepts, approaching human levels of performance.
- The study evaluates the ongoing relevance and integrity of coding assignments amidst technological advancements.
- The code used in the research is openly accessible on GitHub for transparency.
- The study uses a blinded marking approach to assess code written by both students and AI.
- Physics coding focuses on simulations and data analysis, emphasizing clear, well-labeled plots.
- The study contrasts with computer science scenarios focusing on readability and maintainability.
- ChatGPT's suitability as a coding tool for physics education is evaluated through 14 plots.
- The study involves essential laboratory practices, electronics, and coding tasks over 10 weeks.
- Submissions from 55 out of 103 participants were randomly selected for evaluation.
- Each assignment includes tasks graded automatically and manually, contributing to the final coding mark.
- Pre-processing assignment notebooks is crucial for aligning with AI capabilities.
- Prompt engineering significantly improves AI performance in coding assignments.
- GPT-4 with prompt engineering scored 81.1%, while students averaged 91.1%.
- Combining student and AI work scored lower than AI-only submissions due to variability in student work quality.
- Evaluators used a lyer scale to assign authorship scores to submissions.
- Human-created work scored higher on average than AI-generated content.
- Advanced GPT-4 models showed improvement over GPT-3.5, especially with prompt engineering.
- Educators should consider integrating AI into educational practices like pair programming tools.
- Lower performance of AI in raw input categories suggests students benefit more from completing assignments themselves.
- Extensive prompt engineering raises concerns about academic integrity.
- Markers successfully identified AI-generated work based on design differences and plot characteristics.

# INSIGHTS:
- Programming skills' growing importance is reflected in widespread inclusion of coding courses in universities.
- Advanced LLMs prompt reconsideration of traditional coding assessments in educational settings.
- AI's impact on practical coding curriculum is significant in diverse assessment environments like physics degrees.
- High-quality AI-generated work influences essay-based assessments more than hands-on lab work or presentations.
- Continuous assessment of coding assignments' relevance and integrity is crucial amidst technological advancements.
- Blinded marking approach helps evaluate AI's effectiveness in student coding tasks.
- Clear, well-labeled plots are essential in physics coding for simulations and data analysis.
- Prompt engineering enhances AI performance but raises academic integrity concerns.
- Combining student and AI work may result in lower scores due to variability in student work quality.
- Human-created content still tends to be of higher quality than AI-generated content.

# QUOTES:
- "Coding courses are increasingly included in university programs worldwide, highlighting programming skills' growing importance."
- "Advanced LLMs like Codex prompt reconsideration of coding assessments in educational settings."
- "The study focuses on AI's impact on practical coding curriculum in a 10-week physics course."
- "Physics degrees involve diverse assessments, including lab experiments, presentations, written exams, essays, and coding tasks."
- "AI's influence on essay-based assessments is becoming more pronounced with high-quality AI-generated work."
- "LLMs are improving in their comprehension of physics concepts, approaching human levels of performance."
- "The study evaluates the ongoing relevance and integrity of coding assignments amidst technological advancements."
- "The code used in the research is openly accessible on GitHub for transparency."
- "The study uses a blinded marking approach to assess code written by both students and AI."
- "Physics coding focuses on simulations and data analysis, emphasizing clear, well-labeled plots."
- "The study contrasts with computer science scenarios focusing on readability and maintainability."
- "ChatGPT's suitability as a coding tool for physics education is evaluated through 14 plots."
- "The study involves essential laboratory practices, electronics, and coding tasks over 10 weeks."
- "Submissions from 55 out of 103 participants were randomly selected for evaluation."
- "Each assignment includes tasks graded automatically and manually, contributing to the final coding mark."
- "Pre-processing assignment notebooks is crucial for aligning with AI capabilities."
- "Prompt engineering significantly improves AI performance in coding assignments."
- "GPT-4 with prompt engineering scored 81.1%, while students averaged 91.1%."
- "Combining student and AI work scored lower than AI-only submissions due to variability in student work quality."
- "Evaluators used a lyer scale to assign authorship scores to submissions."

# HABITS:
- Regularly include coding courses in university programs to highlight programming skills' importance.
- Continuously assess the relevance and integrity of coding assignments amidst technological advancements.
- Use a blinded marking approach to evaluate code written by both students and AI.
- Emphasize clear, well-labeled plots for simulations and data analysis in physics coding tasks.
- Integrate prompt engineering techniques to enhance AI performance in educational settings.
- Consider combining student and AI work cautiously due to variability in student work quality.

# FACTS:
- Coding courses are increasingly included in university programs worldwide.
- Advanced LLMs like Codex prompt reconsideration of traditional coding assessments.
- Physics degrees involve diverse assessments including lab experiments, presentations, written exams, essays, and coding tasks.
- High-quality AI-generated work influences essay-based assessments more than hands-on lab work or presentations.
- Continuous assessment of coding assignments' relevance and integrity is crucial amidst technological advancements.

# REFERENCES:
- GitHub (for accessing the code used in the research)
  
# ONE-SENTENCE TAKEAWAY
Advanced LLMs like Codex necessitate reevaluating traditional coding assessments' relevance and integrity amidst rapid technological advancements.

# RECOMMENDATIONS:
- Regularly include coding courses in university programs to highlight programming skills' importance.
- Continuously assess the relevance and integrity of coding assignments amidst technological advancements.
- Use a blinded marking approach to evaluate code written by both students and AI.
- Emphasize clear, well-labeled plots for simulations and data analysis in physics coding tasks.
- Integrate prompt engineering techniques to enhance AI performance in educational settings.