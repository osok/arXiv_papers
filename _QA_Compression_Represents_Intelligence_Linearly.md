# SUMMARY
The paper presents a method to evaluate the intelligence of large language models (LLMs) using compression efficiency as a reliable metric.

# IDEAS:
- The new method aims to solve evaluating LLMs' intelligence more reliably and practically.
- Establishes a correlation between compression efficiency and intelligence in LLMs.
- Addresses limited empirical evidence on compression and intelligence relationship.
- Uses compression efficiency as a metric to assess LLMs' abilities.
- Provides a stable, flexible, and unsupervised way to evaluate model performance.
- Mitigates issues like overfitting, data contamination, and subjective judgment.
- Evaluates pre-trained LLMs of different sizes and organizations.
- Assesses models on knowledge, common sense, coding, and mathematical reasoning.
- Measures compression efficiency using average bits per character (BPC).
- Correlation evaluated using Pearson correlation coefficient and root mean square error (RMSE).
- Focuses on well-trained base models to ensure evaluated intelligence is manifest.
- Establishes linear correlation between compression efficiency and intelligence as universal principle.
- Addresses potential issues like overfitting benchmarks and selecting appropriate compression corpora.
- Explores impact of compression corpus size on BPC metric reliability.
- Extends analysis to cross-ability tasks demonstrating effectiveness of compression efficiency.
- Offers reliable and unsupervised metric for evaluating LLMs' abilities.
- Allows flexible and stable evaluation of LLMs across various domains.
- Can be extended to assess LLMs across different model sizes, tokenizers, and pre-training data distributions.
- Provides empirical support for belief that superior compression indicates greater intelligence.
- Validated through empirical study examining relationship between compression and intelligence.
- Conducted experiments across 30 public LLMs and 12 diverse benchmarks.
- Found Pearson correlation coefficient of around -0.95 for each evaluated domain of intelligence.
- Demonstrated linear correlation across different model sizes, tokenizers, and pre-training data distributions.
- Highlighted importance of selecting appropriate compression corpora for specific domain of study.
- Showed that compression corpus size impacts correlation strength.
- Achieved linear correlation between compression efficiency and intelligence in LLMs.
- Results demonstrated compression efficiency as stable, flexible, and reliable metric.
- Limitations include focus on base models excluding fine-tuned models.
- Study concentrates on short to medium context regimes, deferring long context scenarios.
- Conclusions may only apply to well-trained models with fully emerged abilities.

# INSIGHTS:
- Compression efficiency can serve as a reliable metric for evaluating LLMs' intelligence.
- Linear correlation between compression efficiency and intelligence is a universal principle.
- Superior compression indicates greater intelligence in LLMs across various domains.
- Method mitigates overfitting, data contamination, and subjective judgment issues.
- Empirical study validates strong correlation between compression efficiency and intelligence.

# QUOTES:
- "The new method aims to solve the problem of evaluating the intelligence of large language models."
- "Establishes a correlation between compression efficiency and intelligence."
- "Uses compression efficiency as a metric to assess LLMs' abilities."
- "Provides a stable, flexible, and unsupervised way to evaluate model performance."
- "Mitigates issues such as overfitting, data contamination, and subjective judgment."
- "Evaluates pre-trained LLMs of different sizes and from diverse organizations."
- "Assesses models on knowledge, common sense, coding, and mathematical reasoning."
- "Measures compression efficiency using the average bits per character (BPC) metric."
- "Correlation evaluated using Pearson correlation coefficient and root mean square error (RMSE)."
- "Focuses on well-trained base models to ensure evaluated intelligence is manifest."
- "Establishes linear correlation between compression efficiency and intelligence as universal principle."
- "Addresses potential issues like overfitting benchmarks and selecting appropriate compression corpora."
- "Explores impact of the size of the compression corpus on BPC metric reliability."
- "Extends analysis to crossability tasks demonstrating effectiveness of using compression efficiency."
- "Offers reliable and unsupervised metric for evaluating LLMs' abilities."
- "Allows flexible and stable evaluation of LLMs across various domains."
- "Can be extended to assess LLMs across different model sizes, tokenizers, context window lengths."
- "Provides empirical support for belief that superior compression indicates greater intelligence."
- "Validated through empirical study examining relationship between compression and intelligence."
- "Conducted experiments across 30 public LLMs and 12 diverse benchmarks."

# HABITS:
- Evaluating pre-trained LLMs of different sizes from diverse organizations for comprehensive analysis.
- Using average bits per character (BPC) metric to measure compression efficiency.
- Focusing on well-trained base models to ensure evaluated intelligence is manifest.
- Conducting experiments across multiple public LLMs and diverse benchmarks for validation.

# FACTS:
- The method establishes a correlation between compression efficiency and intelligence in LLMs.
- Uses average bits per character (BPC) metric to measure compression efficiency.
- Pearson correlation coefficient around -0.95 indicates strong linear relationship.
- Evaluates pre-trained LLMs on knowledge, common sense, coding, mathematical reasoning.
- Conducted experiments across 30 public LLMs and 12 diverse benchmarks.

# REFERENCES:
None mentioned in the input.

# ONE-SENTENCE TAKEAWAY
Compression efficiency serves as a reliable metric for evaluating the intelligence of large language models.

# RECOMMENDATIONS:
- Use compression efficiency as a metric to assess LLMs' abilities reliably and practically.
- Evaluate pre-trained LLMs of different sizes from diverse organizations for comprehensive analysis.
- Measure compression efficiency using the average bits per character (BPC) metric.
- Focus on well-trained base models to ensure evaluated intelligence is manifest.
- Conduct experiments across multiple public LLMs and diverse benchmarks for validation.