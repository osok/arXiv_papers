# SUMMARY
Researchers explore multi-dimensional features in language models, identifying circular representations for days and months, and propose new interpretability methods.

# IDEAS:
- Multi-dimensional features reduce a model's representation space.
- Sparse autoencoders can discover multi-dimensional features in GPT-2 and Mistol 7B.
- Circular representations for days and months are novel findings in language models.
- Modular addition tasks demonstrate the use of circular representations by models.
- Intervention experiments confirm models utilize circular representations for these tasks.
- Techniques to break down LLM hidden states reveal circular patterns in days and months.
- Linear representations in word embedding methods like GloVe and Word2Vec are explored.
- Nonlinear features in models include fractal structures and polytopes.
- Circuits within models help understand specific behaviors like identifying indirect objects.
- Interpretability in arithmetic problems includes handling modular arithmetic and basic operations.
- Decomposing hidden states into functions of input features is crucial for interpretability.
- Meaningful features should be irreducible, focusing on statistical reducibility.
- Separability index and Epsilon mixture index quantify feature reducibility.
- New superposition hypothesis emphasizes independence between irreducible multi-dimensional features.
- Sparse autoencoders break down hidden states into sparse vector sums from an overcomplete basis.
- Clustering dictionary elements helps discover irreducible multi-dimensional features.
- Circular subspaces play a significant role in computing gamma for weekday tasks.
- Explanation via regression (EVR) explains variance in hidden states using linear regressions.
- EVR reveals a circle in gamma, suggesting trigonometry-based algorithms in later MLP layers.
- Higher dimensional features challenge the one-dimensional linear representation hypothesis.
- Generalizing features to higher dimensions enhances understanding of language model representations.

# INSIGHTS:
- Multi-dimensional features significantly reduce the representation space of language models.
- Circular representations for days and months are crucial for certain computational tasks.
- Sparse autoencoders effectively identify irreducible multi-dimensional features in language models.
- Independence between low-dimensional irreducible features enhances model efficiency.
- Clustering dictionary elements based on similarities uncovers interpretable structures.
- Circular subspaces are essential for accurate computation in modular arithmetic tasks.
- Explanation via regression (EVR) provides a comprehensive understanding of hidden states.
- Trigonometry-based algorithms are used in later MLP layers for modular addition problems.
- Higher dimensional features offer deeper insights into language model representations.
- Exploring complex circuits in advanced models leads to formally verifiable programs.

# QUOTES:
- "We identify circular representations for the day of the week and month of the year."
- "Sparse autoencoders can uncover irreducible multi-dimensional features."
- "Circular subspaces play a significant role in computing gamma."
- "Our work challenges the one-dimensional linear representation hypothesis."
- "We advocate for exploring higher dimensional features to better understand model representations."
- "Explanation via regression (EVR) helps us identify what information can be extracted."
- "Clustering dictionary elements based on their similarities can help in discovering these features."
- "Circular representations are crucial for certain problems."
- "Sparse autoencoders break down hidden states into sparse vector sums from an overcomplete basis."
- "Higher dimensional features challenge the one-dimensional linear representation hypothesis."

# HABITS:
- Using sparse autoencoders to identify multi-dimensional features in language models.
- Clustering dictionary elements based on similarities to uncover interpretable structures.
- Applying layer-wise activation patching to isolate circuits for specific tasks.
- Conducting intervention experiments to confirm model utilization of circular representations.
- Iteratively adding hand-chosen functions to explain variance in hidden states.

# FACTS:
- Multi-dimensional features reduce a model's representation space.
- Circular representations for days and months are novel findings in language models.
- Sparse autoencoders can discover multi-dimensional features in GPT-2 and Mistol 7B.
- Modular addition tasks demonstrate the use of circular representations by models.
- Techniques to break down LLM hidden states reveal circular patterns in days and months.

# REFERENCES:
- GPT-2
- Mistol 7B
- Llama 38B
- GloVe
- Word2Vec

# ONE-SENTENCE TAKEAWAY
Exploring multi-dimensional features, especially circular representations, enhances our understanding of language model interpretability and efficiency.

# RECOMMENDATIONS:
- Use sparse autoencoders to identify irreducible multi-dimensional features in language models.
- Cluster dictionary elements based on similarities to uncover interpretable structures.
- Apply layer-wise activation patching to isolate circuits for specific tasks.
- Conduct intervention experiments to confirm model utilization of circular representations.
- Iteratively add hand-chosen functions to explain variance in hidden states.